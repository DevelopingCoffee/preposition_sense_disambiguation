\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{scrpage2}
\usepackage{color}
\usepackage{titlesec}
\pagestyle{scrheadings}
\usepackage{ulem, contour}
\usepackage{hyperref}
\usepackage{listings}

\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

\renewcommand{\ULdepth}{1.8pt}
\contourlength{0.8pt}

\newcommand{\customuline}[1]{%
  \uline{\phantom{#1}}%
  \llap{\contour{white}{#1}}%
}

\ihead{Flair}
\chead{Preposition sense disambiguation}
\ohead{Text2Scene}
\cfoot{\pagemark}
\setheadsepline{.5pt}

\definecolor{gray}{rgb}{0.33, 0.33, 0.33}
\definecolor{greengreen}{rgb}{0.0, 0.56, 0.0}
\definecolor{fgreen}{rgb}{0.13, 0.55, 0.13}
\definecolor{grellow}{rgb}{0.68, 1.0, 0.18}
\definecolor{orange}{rgb}{1.0, 0.49, 0.0}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

%List setup
\lstdefinestyle{python}{
	language     = Python,
	basicstyle   = \small\ttm,
	keywordstyle = \small\color{deepblue}\ttb,
	commentstyle = \color{gray},
	emph={__init__,__contains__,self,encoding},
	emphstyle=\small\ttb\color{deepred},   
	stringstyle=\color{deepgreen}, 
	xleftmargin = \parindent
}
\lstset{
	frame = single,
	language=Python,
	breaklines=true,
	tabsize=4,
	escapeinside={(*@}{@*)}
}

\newcommand\pythonstyle{\lstset{
    frame=single,
	language=Python,
	breaklines=true,
	tabsize=4,
	escapeinside={(*@}{@*)},
    style=python            
}}

% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}


\begin{document}
\tableofcontents
\newpage

\section{Einleitung}
\begin{flushleft}
Im Praktikum \textit{Text2Sene} geht es darum, aus Textbeschreibungen Szenen zu erstellen. Dabei wurde die Arbeit unterteilt; wir beschäftigen uns mit der Thematik der \textit{preposition sense disambiguation} (Sinneszuordnung und -erkennung von Präpositionen). Für diese Aufgabe haben wir verschiedene \textit{State-of-the-Art-Verfahren} begutachtet. Schlussendlich haben wir uns dafür entschieden, einerseits einen \textit{Semi-supervised} Ansatz umzusetzen und daneben KIs mit Hilfe der frameworks FlairNLP, AllenNLP und Huggingface zu programmieren.
\end{flushleft}

\section{FlairNLP}
\begin{flushleft}
FlairNLP ist ein Framework, das speziell für NLP-Aufgaben konzipiert ist. Für unsere Aufgabe nutzen wir einen \textit{text classifier}, der wie der Name sagt, eine Eingabe klassifiziert und dadurch die Präposition dem zugehörigen Sinn zuordnet.
\end{flushleft}

\subsection{Vorgehen [Training]}
\begin{flushleft}
Damit einer Präposition ein Sinn zugeordnet werden kann, passieren einige Dinge. Der Hauptteil des Projekts besteht aus einer NLP-KI mit dem Flair-framework.

Damit eine Eingabe verarbeitet werden kann, muss diese zunächst vorbereitet werden. Dazu werden die Daten aus den xml-Dateien gelsen und in einer csv-Datei mit dem entsprechenden Format für Flair abgespeichert. Hierbei wird das standard-Format (\_\_label\_\_$<$label$>$) verwendet. Die Trainingsdaten werden in drei Dateien aufgeteilt, dabei werden 80\% Training, 10\% Dev und weitere 10\% Test zugeschrieben.

Nachdem die Daten im csv-Format vorliegen, wird daraus ein Korpus erstellt. Dazu wird ein \textit{Dictionary} und die entsprechenden Embeddings erstellt. Anschließend wird der \textit{Classifier} erstellt und das Training beginnt.\footnote{Für eine genauere Erklärung bzgl. des Classifiers, des Korpus und des Dictionary verweisen wir auf die offizielle FlairNLP-Dokumentation.}
\end{flushleft}

\subsection{Anwendung}
\begin{flushleft}

\end{flushleft}

\subsubsection{Trainieren}
\begin{flushleft}

\end{flushleft}

\subsubsection{Satz predicten}
\begin{flushleft}
Um einen Satz zu predicten, ist nicht viel erforderlich. Beim Aufrufen muss lediglich eine Liste von \textit{Strings} übergeben werden. Wurde beim erstellen des Objektes angegeben, dass nicht tokenisiert werden soll, werden die übergebenen Sätze nur mit einem \textit{SpaceTokenizer} tokenisiert. Die übergebenen Sätze dürfen zudem noch nicht markiert sein - die \textbf{Markierung der Präpositionen wird automatisch} mit dem \textit{Sequence Tagger} (\hyperlink{SeqTag}{$\uparrow$}) \textbf{vollzogen}.

Bevor predictet wird, wird zuerst geprüft, ob ein \textit{classifier} vorhanden ist. Wenn nicht, wird wenn möglich einer importiert, ansonsten ein neuer erstellt - jedoch wird \textbf{immer} erst versucht, einen existierenden zu importieren. Hierbei ist wichtig, dass das bei der Erstellung des Objekts angegebene Verzeichnis als Quelle für Imports und Exports herangezogen wird. 
\end{flushleft}

\subsection{Sequence Tagger - Präpositionen markieren}
\begin{flushleft}
\hypertarget{SeqTag}{Der} \textit{Sequence Tagger} ist notwenidg, um in einem Satz die Präposition zu markieren, die klassifiziert werden soll, v.a. in Sätzen, in denen mehrere vorhanden sind.

Hierbei ist zu beachten, dass für eine einfache Anwendung des Flair Projekts zum predicten der Präposition in einem Satz das Verstehen und / oder Anwenden dieses Taggers \textbf{nicht} notwendig ist.
\end{flushleft}

\subsubsection{Anwendung}
\begin{flushleft}
Der \textit{Sequence Tagger} ist ganz simpel zu benutzen. Zunächst muss wie gewöhnlich ein Objekt der Klassen erzeugt werden. Anschließend ist mit der Methode set\_input() die Eingabe zu setzen. Die Eingabe muss eine Liste von \textit{Strings} sein. Ist dies getan, kann mit do\_tagging() das taggen gestartet werden. Diese Methode gibt dann eine Liste mit den reultierenden \textit{Strings} zurück. Hierbei ist zu beachten, dass bei Eingabe eines Satzes mit zwei Präpositionen \textbf{zwei} Sätze zurückgegeben werden!
\end{flushleft}

\subsubsection{Funktionsweise}
\begin{flushleft}
FlairNLP bietet mehrere bereits vortrainierte \textit{Sequence Tagger}. Wir nutzen für unser Projekt den \textit{Part-of-Speech Tagger}. Mit diesem wird der Satz zunächst predictet, wodurch jedem Wort der entsprechende Tag zugeordnet wird. Da wir uns aber nur für Präpositionen interessieren, löschen wir alle anderen Tags. Zeitgleich werden die Präpositionen aus dem Satz extrahiert, um sie später gezielt wieder einzusetzen und dabei jede Preposition in einem individuellen Satz markieren zu können.
\end{flushleft}

\subsubsection{Programm}
\begin{flushleft}
Der \textit{(Sequence) Tagger} ist in dem script \textit{model\_flair.py} enthalten.
\end{flushleft}
\begin{itemize}
\item \_\_init\_\_: In der Initialisierungs-Methode Wird lediglich der zuvor beschriebene Tagger von Flair geladen.
\item set\_input: Diese Methode dient dazu, eine Liste an \textit{Strings} zu übergeben, die getaggt werden sollen.
\item do\_tagging: Diese Methode taggt die zuvor in der set\_input Methode übergeben Sätze. Rückgabeparameter ist eine Liste an \textit{Strings}. Diese Liste kann u.U. größer sein, als die Liste der Eingaben.
\end{itemize}

\subsection{Projektaufbau}
\begin{flushleft}
Das Flair-Projekt umfasst hauptsächlich zwei Dateien:
\end{flushleft}
\begin{itemize}
\item[•] model\_flair.py - Diese Datei enthält die Basisklasse(n) für das Projekt. Dabei sind nur die beiden Methoden \textit{train} und \textit{predict} der Klasse \textit{BaseModel} für den einfachen Gebrauch notwendig. Erstere vollzieht das Training mit den der Methode angegebenen Daten (Übergabeparameter ist ein Verzeichnis) und zweitere predictet eine Liste an Sätzen (\textit{Strings}), die übergeben werden.
\item[•] flair\_test.py - Dieses script dient dazu, einen simplen test des Flair-Models durchzuführen. Es nimmt \textit{command line arguments} entgegen, um zwischen Training und Testen, sowie ob ein Tokenizer verwendet werden soll, zu entscheiden. Das erste Argument muss dabei ein \textbf{boolean} sein und bezeichnet die Wahl für (Argument = \textit{False}) oder gegen (Argument = \textit{True}) einen Tokenizer. Das zweite Argument ist hingegen die Wahl für Training oder Test. Um ein Training zu starten muss "train" (\textit{String}) eingegeben werden; Jede andere Eingabe wählt das Testen.
\end{itemize}

\subsubsection{Aufbau des Classifiers und Korpus}
\begin{flushleft}
DEr Classifier ist der Hauptbestandteil dieses Flair-Projekts. Für das Training dieses Classifiers ist aber ein Korpus notwendig, in dem die Trainingsdaten verarbeitet werden.
\end{flushleft}

\paragraph{Korpus}
\begin{flushleft}
Bevor ein Classifier erstellt werden kann, muss zuerst ein Korpus erstellt werden. Dies geschieht in der Methode \textit{\_create\_corpus}.

\begin{python}
col_name_map = {0: "label", 1: "text"}
\end{python}

Die column name map (\textit{col\_name\_map}) wird hier angegeben und enthält die Information, wo in der Datei der Daten die label und wo der Text steht.

\begin{python}
if (not(self.use_tokenizer)):
	tokenizer = SpaceTokenizer()
else:
	tokenizer = SegtokTokenizer()
\end{python}

Als Tokenizer werden entweder der flair Tokenizer SegTok oder ein SpaceTokenizer verwendet, je nachdem ob angegeben ist, dass ein Tokenizer verwendet werden soll, oder nicht. Die Tokenizer können auch angepasst werden.

\begin{python}
self.__corpus: Corpus = CSVClassificationCorpus(data_folder=data_dir,
    column_name_map=col_name_map,
    tokenizer=tokenizer)
\end{python}

Der Korpus wird dann mit der colun name map, den Trainingsdaten und dem Tokenizer erstellt und in der Klassenvariable \textit{\_\_corpus} gespeichert.
\end{flushleft}

\paragraph{Classifier}

\begin{flushleft}
Existiert ein Korpus, kann ein Classifier erstellt werden.

\begin{python}
label_dict = self.__corpus.make_label_dictionary()
\end{python}

Zuerst wird dazu ein dictionary der label erstellt.

\begin{python}
word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'),FlairEmbeddings('news-backward-fast')]

document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512,reproject_words=True,reproject_words_dimension=256)
\end{python}

Anschließend wenden wir Embeddings an. \textbf{\textcolor{red}{WIP}}

\begin{python}
self.__classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, multi_label=False)
\end{python}

Nachdem die Embeddings angewandt wurden, wird der classifier erstellt. \textbf{\textcolor{red}{WIP}}

\end{flushleft}


%----------------------

\begin{flushleft}

\textbf{\textcolor{red}{WIP [old description]}}

Nachdem der Korpus erzeugt wurde, werden die Embeddings erzeugt. Hierbei können mehrere Embeddings durch sog. \textit{pool-embeddings} zusammen genutzt werden. Wir haben uns (hier) für OneHotEmbeddings und WordEmbeddings (Typ \textit{glove)} entschieden\footnote{In anderen Dateien haben wir auch andere Embeddings getestet, aber mit diesen die besten Ergebnisse erzielt.}.

Anschließend erstellen wir den Trainer auf Basis des zuvor erzeugten oder geladenen Classifier und Korpus und beginnen das Training. Hierbei können verschiedene Einstellungen vorgenommen werden. Zunächst wird das \textit{output-directory} angegeben., welches wir mit \textit{resources} angegeben haben. In diesem Verzeichnis werden dann logs und die Models abgespeichert. Die \textit{learning rate} haben wir auf dem Sdandartwert belassen, ebenso die beiden weiteren Parameter. Die \textit{patience} kann variabel angepasst werden. Sie verursacht, dass das Training bei zu vielen Epochen ohne Verbesserung \textbf{hintereinander} die Lernrate verringert oder das Training abgebrochen wird. Je höher die patience, desto mehr Epochen ohne Verbesserung können vorkommen. Der letzte Parameter ist die maximale Anzahl an Epochen. Wir haben einige Tausend Epochen trainiert. Dieses Training kann aber auch dauern; Auswirkungen auf die tRainingszeit haben u.a. auch die verwedeten Embeddings.
\end{flushleft}

\subsubsection{Aufbau des Trainings}
\begin{flushleft}

\end{flushleft}

\subsubsection{Aufbau des Predictors}
\begin{flushleft}
Der Predictor dient dazu, die Fertige KI anzuwenden. Um einen Satz korrekt zu predicten, muss in diesem die Präposition markiert werden. Diese Markierung ist ein html-Tag, $<$head$>$, bzw. $<$\textbackslash head$>$ und wird mit Hilfe des zuvor beschriebenen Taggers eingefügt. Diese Sätze werden dann mit der vom \textit{flair-classifier} bereitgestellten Methode predictet.
\end{flushleft}

\newpage

\section{AllenNLP}

\subsection{Vorgehen}

\subsection{Programm}

\newpage

\section{Blabla}

\end{document}