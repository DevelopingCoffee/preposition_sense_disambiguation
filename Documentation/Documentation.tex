\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{scrpage2}
\usepackage{color}
\usepackage{titlesec}
\pagestyle{scrheadings}
\usepackage{ulem, contour}
\usepackage{hyperref}
\usepackage{listings}

\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

\renewcommand{\ULdepth}{1.8pt}
\contourlength{0.8pt}

\newcommand{\customuline}[1]{%
  \uline{\phantom{#1}}%
  \llap{\contour{white}{#1}}%
}

\ihead{Flair}
\chead{Preposition sense disambiguation}
\ohead{Text2Scene}
\cfoot{\pagemark}
\setheadsepline{.5pt}

\definecolor{gray}{rgb}{0.33, 0.33, 0.33}
\definecolor{greengreen}{rgb}{0.0, 0.56, 0.0}
\definecolor{fgreen}{rgb}{0.13, 0.55, 0.13}
\definecolor{grellow}{rgb}{0.68, 1.0, 0.18}
\definecolor{orange}{rgb}{1.0, 0.49, 0.0}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

%List setup
\lstdefinestyle{python}{
	language     = Python,
	basicstyle   = \small\ttm,
	keywordstyle = \small\color{deepblue}\ttb,
	commentstyle = \color{gray},
	emph={__init__,__contains__,self,encoding},
	emphstyle=\small\ttb\color{deepred},   
	stringstyle=\color{deepgreen}, 
	xleftmargin = \parindent
}
\lstset{
	frame = single,
	language=Python,
	breaklines=true,
	tabsize=4,
	escapeinside={(*@}{@*)}
}

\newcommand\pythonstyle{\lstset{
    frame=single,
	language=Python,
	breaklines=true,
	tabsize=4,
	escapeinside={(*@}{@*)},
    style=python            
}}

% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}


\begin{document}
\tableofcontents
\newpage

\section{Einleitung}
\begin{flushleft}
Im Praktikum \textit{Text2Sene} geht es darum, aus Textbeschreibungen Szenen zu erstellen. Dabei wurde die Arbeit unterteilt; wir beschäftigen uns mit der Thematik der \textit{preposition sense disambiguation} (Sinneszuordnung und -erkennung von Präpositionen). Für diese Aufgabe haben wir verschiedene \textit{State-of-the-Art-Verfahren} begutachtet. Schlussendlich haben wir uns dafür entschieden, einerseits einen \textit{Semi-supervised} Ansatz umzusetzen und daneben KIs mit Hilfe der frameworks FlairNLP, AllenNLP und Huggingface zu programmieren.
\end{flushleft}

\section{FlairNLP}
\begin{flushleft}
FlairNLP ist ein Framework, das speziell für NLP-Aufgaben konzipiert ist. Für unsere Aufgabe nutzen wir einen \textit{text classifier}, der wie der Name sagt, eine Eingabe klassifiziert und dadurch die Präposition dem zugehörigen Sinn zuordnet.
\end{flushleft}

\subsection{Vorgehen}
\begin{flushleft}
Damit einer Präposition ein Sinn zugeordnet werden kann, passieren einige Dinge. Der Hauptteil des Projekts besteht aus einer NLP-KI mit dem Flair-framework.

Damit eine Eingabe verarbeitet werden kann, muss diese zunächst vorbereitet werden. Dazu werden die Daten aus den xml-Dateien gelsen und in einer csv-Datei mit dem entsprechenden Format für Flair abgespeichert. Hierbei wird das standard-Format (\_\_label\_\_$<$label$>$) verwendet. Die Trainingsdaten werden in drei Dateien aufgeteilt, dabei werden 80\% Training, 10\% Dev und weitere 10\% Test zugeschrieben.

Nachdem die Daten im csv-Format vorliegen, wird daraus ein Korpus erstellt. Dazu wird ein \textit{Dictionary} und die entsprechenden Embeddings erstellt. Anschließend wird der \textit{Classifier} erstellt und das Training beginnt.
\end{flushleft}

\subsection{Anwendung}
\begin{flushleft}
Für eine reibungslose Anwendung des Programmes müssen einige Dinge beachtet werden, denn es kann immer nur eine Präposition gleichzeitig klassifiziert werden. Deshalb wird ein \textit{Sequence Tagger} benötigt, der die Präposition markiert, die klassifiziert werden soll. Dieser ist im \hyperlink{SeqTag}{Abschnitt 2.3} erklärt.
\end{flushleft}

\subsubsection{Satz predicten}
\begin{flushleft}
Um einen Satz zu predicten wird das script \textit{predict.py} benötigt. Beim Aufrufen kann der Satz, der predictet werden soll mit übergeben werden. Wichtig dabei ist, dass der Satz zuvor mit dem \textit{Sequence Tagger} (\hyperlink{SeqTag}{$\uparrow$}) präpariert wurde. Sollte dies nicht geschehen sein, kann ein fehlerhaftes Ergebnis ausgegeben werden.
\end{flushleft}

\subsection{Sequence Tagger}
\begin{flushleft}
\hypertarget{SeqTag}{Der} \textit{Sequence Tagger} ist notwenidg, um in einem Satz die Präposition zu markieren, die klassifiziert werden soll, v.a. in Sätzen, in denen mehrere vorhanden sind.
\end{flushleft}

\subsubsection{Anwendung}
\begin{flushleft}
Der \textit{Sequence Tagger} ist ganz simpel zu benutzen. Zunächst muss wie gewöhnlich ein Objekt der Klassen erzeugt werden. Anschließend ist mit der Methode set\_input() die Eingabe zu setzen. Die Eingabe muss eine Liste von \textit{Strings} sein. Ist dies getan, kann mit do\_tagging() das taggen gestartet werden. Diese Methode gibt dann eine Liste mit den reultierenden \textit{Strings} zurück. Hierbei ist zu beachten, dass bei Eingabe eines Satzes mit zwei Präpositionen \textbf{zwei} Sätze zurückgegeben werden!
\end{flushleft}

\subsubsection{Funktionsweise}
\begin{flushleft}
FlairNLP bietet mehrere bereits vortrainierte \textit{Sequence Tagger}. Wir nutzen für unser Projekt den \textit{Part-of-Speech Tagger}. Mit diesem wird der Satz zunächst predictet, wodurch jedem Wort der entsprechende Tag zugeordnet wird. Da wir uns aber nur für Präpositionen interessieren, löschen wir alle anderen Tags. Zeitgleich werden die Präpositionen aus dem Satz extrahiert, um sie später gezielt wieder einzusetzen und dabei jede Preposition in einem individuellen Satz markieren zu können.
\end{flushleft}

\subsubsection{Programm}
\begin{flushleft}
DEr \textit{Sequence Tagger} ist in dem script \textit{flair\_sequence\_tagger.py} enthalten. Er ist so konstruiert, dass er in anderen scripts leicht importiert und verwendet werden kann. Weiterhin beinhaltet das script auch eine beispielhafte Anwendung.
\end{flushleft}
\begin{itemize}
\item \_\_init\_\_: In der Initialisierungs-Methode Wird lediglich der zuvor beschriebene Tagger von Flair geladen.
\item set\_input: Diese Methode dient dazu, eine Liste an \textit{Strings} zu übergeben, die getaggt werden sollen.
\item do\_tagging: Diese Methode taggt die zuvor in der set\_input Methode übergeben Sätze. Rückgabeparameter ist eine Liste an \textit{Strings}. Diese Liste kann u.U. größer sein, als die Liste der Eingaben.
\end{itemize}

\subsection{Projektdateien}
\begin{flushleft}
Das Flair-Projekt umfasst hauptsächlich vier Dateien:
\end{flushleft}
\begin{itemize}
\item[•] Flair\_prepare.py - Diese Datei dient der Vorbereitung der Daten.
\item[•] Dataset\_class.py - Diese Datei enthält wichtige Klassen auf Basis des FlairNLP-Frameworks zum ertsellen des Korpus.
\item[•] flair\_test\_classification\_model.py - Diese Datei dient zum erstellen des \textit{text classifiers} und des Trainings dessen
\item[•] predict.py - Diese Datei enthält den \textit{predictor}, bzw. dient zum testen des Endproduktes.
\end{itemize}
\begin{flushleft}
Zusätzlich zu diesen vier Dateien gibt es noch weitere Dateien, darunter der eine Datei zum \textit{Sequence Tagger}, der in \hyperlink{SeqTag}{Abschnitt 2.3} erklärt ist.

Daneben existieren noch weitere Dateien, die ähnlich zu den vier genannten Dateien sind. Dateien, die ein "\textit{predict}" enthalten, funktionieren wie \textit{predict.py}, Dateien, die ein "\textit{text\_classification\_model}" enthalten, funktionieren wie \textit{flair\_test\_classification\_model.py}, benutzen aber z.B. andere Embeddings.
\end{flushleft}

\subsubsection{Flair\_prepare.py}
\begin{flushleft}
Der erste Schritt befasst sich mit der Vorbereitung der Daten. Wir benutzen für unser Training die Daten des \textbf{SemEval 2007}, die Rund 16.000 Sätze beinhalten zu 34 verschiedenen Prepositionen. Diese Daten sind in xml-Format gegeben, weshalb sie in csv-Format geändert werden müssen.

Als erstes werden die xml-Dateien mit Hilfe der Python-library \textit{xml.etree.ElementTree} ausgelesen. Dabei speichern wir die \textit{senseid} und den Satz in einer Liste. Die \textit{senseid} wird zeitgleich mit dem von Flair benötigten Zusatz \textit{\_\_label\_\_} versehen. Fehlerhafte Einträge - solche, bei denen entweder der Sinn oder der Satz fehlt bzw. fehlerhaft ist - werden zudem aussortiert und deren \textit{instanceid} zur Überprüfung ausgegeben.

Nachdem alle Einträge in die Liste eingefügt wurden, wird diese gemischt und anschließend in \textit{Training}, \textit{Dev} sowie \textit{Test} Dateien \textbf{disjunkt} aufgeteilt (80\% - 10\% - 10\%).
\end{flushleft}

\subsubsection{Dataset\_class.py}
\begin{flushleft}
Die Datei \textit{Dataset\_class.py} enthält die Klassen zum Erstellen des Korpus. Diese sind unverändert aus dem \textbf{GitHub Repository} von Flair übernommen. Für eine genaue Dokumentation dieser beiden Klassen verweisen wir auf die Dokumentation von FlairNLP. Sie sind auf csv-Dateien angepasst.
\end{flushleft}

\subsubsection{Flair\_text\_classification\_model.py}
\begin{flushleft}
Diese datei beinhaltet alle Einstellungen und Bauteile für den \textit{Text classifier}.

\pythonexternal[language=Python, linerange={8-15}]{../flair_sense_disambiguation/Flair_text_classification_model.py}

Als erstes wird der Korpus auf Basis der zuvor erstellten csv-Dateien und der angegebnen \textit{col\_name\_map} erzeugt, sowie ein Dictionary des Korpus errichtet. Flair bietet neben einem csv-Korpus auch andere Formate, wir haben uns aber für csv entschieden, da es ein gängiges Format ist und auch für andere Teilprojekte verwendet werden kann.

\pythonexternal[language=Python, linerange={26-33}]{../flair_sense_disambiguation/Flair_text_classification_model.py}

Nachdem der Korpus erzeugt wurde, werden die Embeddings erzeugt. Hierbei können mehrere Embeddings durch sog. \textit{pool-embeddings} zusammen genutzt werden. Wir haben uns (hier) für OneHotEmbeddings und WordEmbeddings (Typ \textit{glove)} entschieden\footnote{In anderen Dateien haben wir auch andere Embeddings getestet, aber mit diesen die besten Ergebnisse erzielt.}.

\pythonexternal[language=Python, linerange={35-37}]{../flair_sense_disambiguation/Flair_text_classification_model.py}

Nachdem die Embeddings erstellt wurden, kann der Classifier erzeugt werden. Alternativ kann natürlicha uch ein bestehender Classifier geladen werden. Wichtig ist nur, dass dieser Classifier auch die Daten lesen kann, also dem selben Grundaufbau folgt.

\pythonexternal[language=Python, linerange={39-50}]{../flair_sense_disambiguation/Flair_text_classification_model.py}

Bevor das Training startet, wählen wir noch, dass auf einer GPU trainiert werden soll. Da Flair über Torch läuft, kann dies einfach über troch gewählt werden.

Anschließend erstellen wir den Trainer auf Basis des zuvor erzeugten oder geladenen Classifier und Korpus und beginnen das Training. Hierbei können verschiedene Einstellungen vorgenommen werden. Zunächst wird das \textit{output-directory} angegeben., welches wir mit \textit{resources} angegeben haben. In diesem Verzeichnis werden dann logs und die Models abgespeichert. Die \textit{learning rate} haben wir auf dem Sdandartwert belassen, ebenso die beiden weiteren Parameter. Die \textit{patience} kann variabel angepasst werden. Sie verursacht, dass das Training bei zu vielen Epochen ohne Verbesserung \textbf{hintereinander} die Lernrate verringert oder das Training abgebrochen wird. Je höher die patience, desto mehr Epochen ohne Verbesserung können vorkommen. Der letzte Parameter ist die maximale Anzahl an Epochen. Wir haben einige Tausend Epochen trainiert. Dieses Training kann aber auch dauern; Auswirkungen auf die tRainingszeit haben u.a. auch die verwedeten Embeddings.
\end{flushleft}

\subsubsection{predict.py}
\begin{flushleft}
Der Predictor dient dazu, die Fertige KI anzuwenden. Das Programm kann dafür auch aus der Konsole mit Übergabeparameter verwendet werden. Der Übergabeparameter muss dabei ein String sein.

Alternativ kann das Programm auch ohne Übergabeparameter ausgeführt werden. In diesem Fall wird eine Reihe an Testdaten predictet.
\end{flushleft}

\newpage

\section{AllenNLP}

\subsection{Vorgehen}

\subsection{Programm}

\newpage

\section{Blabla}

\end{document}